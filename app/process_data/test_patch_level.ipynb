{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PatchLevel import PatchLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_level = PatchLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = 'data/origin_data/B256/B2/z4907540008741_29ecba73d3d0cc14addd7cba092493d3.jpg'\n",
    "# img = '/mnt/DataK/Project/ThyroidCancer/data/origin_data/B256/B5/z4840977604091_375b3cc2e326154817867ededaa2ca79.jpg'\n",
    "# img = '/mnt/DataK/Project/ThyroidCancer/data/origin_data/B256/B5/z4840977650008_d71ddae75d003a6ece3d7d43ed839b7b.jpg'\n",
    "img = '/mnt/DataK/Project/ThyroidCancer/data/origin_data/B256/B5/z4904745818823_15919ec4cc2a7650351e9c528dede52f.jpg'\n",
    "# img = '/mnt/DataK/Project/ThyroidCancer/data/origin_data/B256/B6/Image_142012.jpg'\n",
    "# img = '/mnt/DataK/Project/ThyroidCancer/data/origin_data/B256/B6/Image_26370.jpg' # cai nay chua on -> co le nen ha conf o step 3 xuong -> hien tai model detect tot nhat van co nhuoc diem la detect nhung te bao qua xa la 1 te bao -> loang vung tap trung trong anh di\n",
    "# img = '/mnt/DataK/Project/ThyroidCancer/data/origin_data/B256/B6/Image_26385.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 608x800 145 cells, 1680.6ms\n",
      "Speed: 10.0ms preprocess, 1680.6ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 800)\n",
      "\n",
      "0: 800x800 142 cells, 2555.7ms\n",
      "Speed: 6.9ms preprocess, 2555.7ms inference, 1.8ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 800x800 45 cells, 2567.2ms\n",
      "Speed: 10.9ms preprocess, 2567.2ms inference, 1.9ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 800x800 236 cells, 2208.9ms\n",
      "Speed: 10.3ms preprocess, 2208.9ms inference, 3.9ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 800x800 14 cells, 2044.3ms\n",
      "Speed: 8.8ms preprocess, 2044.3ms inference, 1.3ms postprocess per image at shape (1, 3, 800, 800)\n",
      "\n",
      "0: 800x800 227 cells, 1900.8ms\n",
      "Speed: 8.0ms preprocess, 1900.8ms inference, 2.2ms postprocess per image at shape (1, 3, 800, 800)\n"
     ]
    }
   ],
   "source": [
    "result = patch_level.process(img_path=img, show_output=(False, False, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PatchLevel.save_result(result, label='B5', img_origin_id='z4904745818823_15919ec4cc2a7650351e9c528dede52f.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = patch_level.step1(img, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = patch_level.step2(result, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = patch_level.step3(result, show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
