Confusion Matrix
[[ 11   9   1]
 [  6  85  18]
 [  2  39 116]]

Classification Report:
              precision    recall  f1-score   support

          B2       0.58      0.52      0.55        21
          B5       0.64      0.78      0.70       109
          B6       0.86      0.74      0.79       157

    accuracy                           0.74       287
   macro avg       0.69      0.68      0.68       287
weighted avg       0.76      0.74      0.74       287




Confusion Matrix:
[[388  12   7]
 [ 21 309  77]
 [ 10  69 328]]

Classification Report:
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       407
           1       0.79      0.76      0.78       407
           2       0.80      0.81      0.80       407

    accuracy                           0.84      1221
   macro avg       0.84      0.84      0.84      1221
weighted avg       0.84      0.84      0.84      1221



Model architecture:
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 vgg16 (Functional)          (None, 7, 7, 512)         14714688  
                                                                 
 flatten_1 (Flatten)         (None, 25088)             0         
                                                                 
 dense_3 (Dense)             (None, 4096)              102764544 
                                                                 
 dropout_2 (Dropout)         (None, 4096)              0         
                                                                 
 dense_4 (Dense)             (None, 4096)              16781312  
                                                                 
 dropout_3 (Dropout)         (None, 4096)              0         
                                                                 
 dense_5 (Dense)             (None, 3)                 12291     
                                                                 
=================================================================
Total params: 134272835 (512.21 MB)
Trainable params: 119558147 (456.08 MB)
Non-trainable params: 14714688 (56.13 MB)







Model architecture:
Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_3 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 vgg16 (Functional)          (None, 7, 7, 512)         14714688  
                                                                 
 flatten_1 (Flatten)         (None, 25088)             0         
                                                                 
 dense_3 (Dense)             (None, 4096)              102764544 
                                                                 
 dropout_2 (Dropout)         (None, 4096)              0         
                                                                 
 dense_4 (Dense)             (None, 4096)              16781312  
                                                                 
 dropout_3 (Dropout)         (None, 4096)              0         
                                                                 
 dense_5 (Dense)             (None, 3)                 12291     
                                                                 
=================================================================
Total params: 134272835 (512.21 MB)
Trainable params: 119558147 (456.08 MB)
Non-trainable params: 14714688 (56.13 MB)
_________________________________________________________________

# Data augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    # rotation_range=20,
    # width_shift_range=0.2,
    # height_shift_range=0.2,
    # shear_range=0.2,
    # zoom_range=0.2,
    # horizontal_flip=True,
    fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1./255)

train_dir = '/content/drive/MyDrive/Colab/Data/train_valid_test_1/train'
# Specify the paths to your train, validation, and test data
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

val_dir = '/content/drive/MyDrive/Colab/Data/train_valid_test_1/valid'
validation_generator = test_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

test_dir = '/content/drive/MyDrive/Colab/Data/train_valid_test_1/test'
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

Found 5700 images belonging to 3 classes.
Found 753 images belonging to 3 classes.
Found 1221 images belonging to 3 classes.

DATA_DIR = '/content/drive/MyDrive/Colab/Data/train_valid_test_1'
# Display information
print("Class Indices: ", train_generator.class_indices)
print(f"Number of training samples: {train_generator.samples}")
print(f"Number of validation samples: {validation_generator.samples}")
print(f"Number of test samples: {test_generator.samples}")

print("Training set:")
for class_name, idx in train_generator.class_indices.items():
    num_files = len(os.listdir(os.path.join(DATA_DIR, 'train', class_name)))
    print(f"{class_name} ({idx}): {num_files} files")

print("Validation set:")
for class_name, idx in validation_generator.class_indices.items():
    num_files = len(os.listdir(os.path.join(DATA_DIR, 'valid', class_name)))
    print(f"{class_name} ({idx}): {num_files} files")

print("Test set:")
for class_name, idx in test_generator.class_indices.items():
    num_files = len(os.listdir(os.path.join(DATA_DIR, 'test', class_name)))
    print(f"{class_name} ({idx}): {num_files} files")

Class Indices:  {'B2': 0, 'B5': 1, 'B6': 2}
Number of training samples: 5700
Number of validation samples: 753
Number of test samples: 1221
Training set:
B2 (0): 1900 files
B5 (1): 1900 files
B6 (2): 1900 files
Validation set:
B2 (0): 251 files
B5 (1): 251 files
B6 (2): 251 files
Test set:
B2 (0): 407 files
B5 (1): 407 files
B6 (2): 407 files

# for c in train_generator.class_indices:
#     classes[train_generator.class_indices[c]] = c
# finetuned_model.classes = classes
# Directory to save the model checkpoints
checkpoint_dir = '/content/drive/MyDrive/Colab/Model/VGG_Model'
os.makedirs(checkpoint_dir, exist_ok=True)

early_stopping = EarlyStopping(patience=5*2)
checkpointer = ModelCheckpoint(
    checkpoint_dir + "/vgg.keras",
    verbose=1,
    save_best_only=True,
)

import os
# from tensorflow.keras.callbacks import ModelCheckpoint

# # Directory to save the model checkpoints
# checkpoint_dir = '/content/drive/MyDrive/Colab/Model/VGG_Model'
# os.makedirs(checkpoint_dir, exist_ok=True)

# # Define the filepath to save the model
# checkpoint_filepath = os.path.join(checkpoint_dir, 'ResNet50_2_0_ver0_1_{epoch:02d}_train_acc_{accuracy:.4f}_val_acc_{val_accuracy:.4f}.keras')

# # Define the callback to save the model after each epoch
# model_checkpoint_callback = ModelCheckpoint(
#     filepath=checkpoint_filepath,
#     save_weights_only=False,
#     monitor='val_accuracy',
#     mode='max',
#     save_best_only=False)

# Train the model with the callback
history = finetuned_model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=100,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    callbacks=[early_stopping, checkpointer])
# Train háº¿t 58p

Epoch 1/100
178/178 [==============================] - ETA: 0s - loss: 0.7456 - accuracy: 0.6978 
Epoch 1: val_loss improved from inf to 0.72888, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg.keras
178/178 [==============================] - 2924s 16s/step - loss: 0.7456 - accuracy: 0.6978 - val_loss: 0.7289 - val_accuracy: 0.7133
Epoch 2/100
178/178 [==============================] - ETA: 0s - loss: 0.4938 - accuracy: 0.7798
Epoch 2: val_loss improved from 0.72888 to 0.60603, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg.keras
178/178 [==============================] - 51s 285ms/step - loss: 0.4938 - accuracy: 0.7798 - val_loss: 0.6060 - val_accuracy: 0.7527
Epoch 3/100
178/178 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.8123
Epoch 3: val_loss did not improve from 0.60603
178/178 [==============================] - 34s 192ms/step - loss: 0.4176 - accuracy: 0.8123 - val_loss: 0.6388 - val_accuracy: 0.7092
Epoch 4/100
178/178 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.8424
Epoch 4: val_loss did not improve from 0.60603
178/178 [==============================] - 34s 193ms/step - loss: 0.3552 - accuracy: 0.8424 - val_loss: 0.6164 - val_accuracy: 0.7554
Epoch 5/100
178/178 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.8520
Epoch 5: val_loss improved from 0.60603 to 0.53223, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg.keras
178/178 [==============================] - 47s 264ms/step - loss: 0.3339 - accuracy: 0.8520 - val_loss: 0.5322 - val_accuracy: 0.7921
Epoch 6/100
178/178 [==============================] - ETA: 0s - loss: 0.2788 - accuracy: 0.8786
Epoch 6: val_loss did not improve from 0.53223
178/178 [==============================] - 36s 200ms/step - loss: 0.2788 - accuracy: 0.8786 - val_loss: 0.6308 - val_accuracy: 0.7867
Epoch 7/100
178/178 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.8945
Epoch 7: val_loss did not improve from 0.53223
178/178 [==============================] - 33s 186ms/step - loss: 0.2377 - accuracy: 0.8945 - val_loss: 0.9329 - val_accuracy: 0.6780
Epoch 8/100
178/178 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.9098
Epoch 8: val_loss did not improve from 0.53223
178/178 [==============================] - 33s 185ms/step - loss: 0.2107 - accuracy: 0.9098 - val_loss: 0.5970 - val_accuracy: 0.7935
Epoch 9/100
178/178 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9238
Epoch 9: val_loss did not improve from 0.53223
178/178 [==============================] - 34s 190ms/step - loss: 0.1860 - accuracy: 0.9238 - val_loss: 0.6939 - val_accuracy: 0.7840
Epoch 10/100
178/178 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.9201
Epoch 10: val_loss did not improve from 0.53223
178/178 [==============================] - 33s 185ms/step - loss: 0.1870 - accuracy: 0.9201 - val_loss: 0.6396 - val_accuracy: 0.7745
Epoch 11/100
178/178 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.9344
Epoch 11: val_loss did not improve from 0.53223
178/178 [==============================] - 34s 192ms/step - loss: 0.1577 - accuracy: 0.9344 - val_loss: 0.6904 - val_accuracy: 0.7976
Epoch 12/100
178/178 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.9508
Epoch 12: val_loss did not improve from 0.53223
178/178 [==============================] - 34s 188ms/step - loss: 0.1240 - accuracy: 0.9508 - val_loss: 0.7786 - val_accuracy: 0.7745
Epoch 13/100
178/178 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.9541
Epoch 13: val_loss did not improve from 0.53223
178/178 [==============================] - 33s 187ms/step - loss: 0.1128 - accuracy: 0.9541 - val_loss: 0.9156 - val_accuracy: 0.7622
Epoch 14/100
178/178 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9598
Epoch 14: val_loss did not improve from 0.53223
178/178 [==============================] - 33s 186ms/step - loss: 0.1032 - accuracy: 0.9598 - val_loss: 0.7317 - val_accuracy: 0.7908
Epoch 15/100
178/178 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.9502
Epoch 15: val_loss did not improve from 0.53223
178/178 [==============================] - 33s 187ms/step - loss: 0.1205 - accuracy: 0.9502 - val_loss: 0.7723 - val_accuracy: 0.7976

accuracy = finetuned_model.evaluate(test_generator, batch_size=12, return_dict=True)

39/39 [==============================] - 6s 149ms/step - loss: 0.6214 - accuracy: 0.8395

# ÄÃ¢y lÃ  káº¿t quáº£ cá»§a ver0_0
# Load the best model from the checkpoints
# best_model_path = '/content/drive/MyDrive/Colab/Model/ResNet_Model/model_epoch_best.h5'  # ÄÆ°á»ng dáº«n Äáº¿n file mÃ´ hÃ¬nh tá»t nháº¥t
# best_model = tf.keras.models.load_model(best_model_path)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

# Predict classes for test set
y_true = test_generator.classes
y_pred = finetuned_model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)

# Calculate confusion matrix
confusion_mtx = confusion_matrix(y_true, y_pred_classes)

print("Confusion Matrix:")
print(confusion_mtx)

# Print classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred_classes))

39/39 [==============================] - 548s 14s/step
Confusion Matrix:
[[135 130 142]
 [142 132 133]
 [142 128 137]]

Classification Report:
              precision    recall  f1-score   support

           0       0.32      0.33      0.33       407
           1       0.34      0.32      0.33       407
           2       0.33      0.34      0.33       407

    accuracy                           0.33      1221
   macro avg       0.33      0.33      0.33      1221
weighted avg       0.33      0.33      0.33      1221

test_dir = '/content/drive/MyDrive/Colab/Data/train_valid_test_1/test'
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    shuffle=False,
    class_mode='categorical')

# Now, when you call predict, the order of the data will be the same as the order of the labels
y_true = test_generator.classes
y_pred = finetuned_model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)

# Calculate confusion matrix
confusion_mtx = confusion_matrix(y_true, y_pred_classes)

print("Confusion Matrix:")
print(confusion_mtx)

# Print classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred_classes))

Found 1221 images belonging to 3 classes.
39/39 [==============================] - 6s 160ms/step
Confusion Matrix:
[[388  12   7]
 [ 21 309  77]
 [ 10  69 328]]

Classification Report:
              precision    recall  f1-score   support

           0       0.93      0.95      0.94       407
           1       0.79      0.76      0.78       407
           2       0.80      0.81      0.80       407

    accuracy                           0.84      1221
   macro avg       0.84      0.84      0.84      1221
weighted avg       0.84      0.84      0.84      1221

early_stopping = EarlyStopping(patience=5*2)
checkpointer = ModelCheckpoint(
    checkpoint_dir + "/vgg_avg_pool.keras",
    verbose=1,
    save_best_only=True,
)

Inp = Input((224, 224, 3))
base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model(Inp)
# x = Flatten()(x)
x = GlobalAveragePooling2D()(x) # sá» lÆ°á»£ng Äáº·c trÆ°ng ÄÆ°á»£c duá»i ra lÃ  512
x = Dense(4096, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(4096, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(3, activation="softmax")(x)
finetuned_model = Model(inputs=Inp, outputs=predictions)

for layer in base_model.layers:
    layer.trainable = False

print('Model architecture:')
finetuned_model.summary()

finetuned_model.compile(
    optimizer=Adam(learning_rate=0.0001), loss="categorical_crossentropy", metrics=["accuracy"]
)

Model architecture:
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_5 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 vgg16 (Functional)          (None, 7, 7, 512)         14714688  
                                                                 
 global_average_pooling2d (  (None, 512)               0         
 GlobalAveragePooling2D)                                         
                                                                 
 dense_6 (Dense)             (None, 4096)              2101248   
                                                                 
 dropout_4 (Dropout)         (None, 4096)              0         
                                                                 
 dense_7 (Dense)             (None, 4096)              16781312  
                                                                 
 dropout_5 (Dropout)         (None, 4096)              0         
                                                                 
 dense_8 (Dense)             (None, 3)                 12291     
                                                                 
=================================================================
Total params: 33609539 (128.21 MB)
Trainable params: 18894851 (72.08 MB)
Non-trainable params: 14714688 (56.13 MB)
_________________________________________________________________

history = finetuned_model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=100,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size,
    callbacks=[early_stopping, checkpointer])
# Train 11p

Epoch 1/100
178/178 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.7144
Epoch 1: val_loss improved from inf to 0.54532, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg_avg_pool.keras
178/178 [==============================] - 36s 190ms/step - loss: 0.6079 - accuracy: 0.7144 - val_loss: 0.5453 - val_accuracy: 0.7391
Epoch 2/100
178/178 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.7655
Epoch 2: val_loss improved from 0.54532 to 0.53879, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg_avg_pool.keras
178/178 [==============================] - 36s 200ms/step - loss: 0.5077 - accuracy: 0.7655 - val_loss: 0.5388 - val_accuracy: 0.7717
Epoch 3/100
178/178 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.7953
Epoch 3: val_loss improved from 0.53879 to 0.47404, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg_avg_pool.keras
178/178 [==============================] - 35s 192ms/step - loss: 0.4577 - accuracy: 0.7953 - val_loss: 0.4740 - val_accuracy: 0.7799
Epoch 4/100
178/178 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.8040
Epoch 4: val_loss did not improve from 0.47404
178/178 [==============================] - 32s 178ms/step - loss: 0.4331 - accuracy: 0.8040 - val_loss: 0.5758 - val_accuracy: 0.7568
Epoch 5/100
178/178 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.8089
Epoch 5: val_loss did not improve from 0.47404
178/178 [==============================] - 34s 190ms/step - loss: 0.4250 - accuracy: 0.8089 - val_loss: 0.4862 - val_accuracy: 0.7867
Epoch 6/100
178/178 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.8276
Epoch 6: val_loss did not improve from 0.47404
178/178 [==============================] - 31s 175ms/step - loss: 0.3898 - accuracy: 0.8276 - val_loss: 0.4871 - val_accuracy: 0.7962
Epoch 7/100
178/178 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.8245
Epoch 7: val_loss did not improve from 0.47404
178/178 [==============================] - 32s 181ms/step - loss: 0.3859 - accuracy: 0.8245 - val_loss: 0.4883 - val_accuracy: 0.7812
Epoch 8/100
178/178 [==============================] - ETA: 0s - loss: 0.3708 - accuracy: 0.8317
Epoch 8: val_loss improved from 0.47404 to 0.42438, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg_avg_pool.keras
178/178 [==============================] - 33s 186ms/step - loss: 0.3708 - accuracy: 0.8317 - val_loss: 0.4244 - val_accuracy: 0.8016
Epoch 9/100
178/178 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.8387
Epoch 9: val_loss improved from 0.42438 to 0.42174, saving model to /content/drive/MyDrive/Colab/Model/VGG_Model/vgg_avg_pool.keras
178/178 [==============================] - 34s 192ms/step - loss: 0.3517 - accuracy: 0.8387 - val_loss: 0.4217 - val_accuracy: 0.7989
Epoch 10/100
178/178 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.8474
Epoch 10: val_loss did not improve from 0.42174
178/178 [==============================] - 32s 181ms/step - loss: 0.3432 - accuracy: 0.8474 - val_loss: 0.4426 - val_accuracy: 0.8016
Epoch 11/100
178/178 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8492
Epoch 11: val_loss did not improve from 0.42174
178/178 [==============================] - 31s 174ms/step - loss: 0.3343 - accuracy: 0.8492 - val_loss: 0.4900 - val_accuracy: 0.7948
Epoch 12/100
178/178 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.8560
Epoch 12: val_loss did not improve from 0.42174
178/178 [==============================] - 32s 177ms/step - loss: 0.3225 - accuracy: 0.8560 - val_loss: 0.4399 - val_accuracy: 0.8098
Epoch 13/100
178/178 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.8654
Epoch 13: val_loss did not improve from 0.42174
178/178 [==============================] - 33s 183ms/step - loss: 0.3080 - accuracy: 0.8654 - val_loss: 0.4829 - val_accuracy: 0.7921
Epoch 14/100
178/178 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.8629
Epoch 14: val_loss did not improve from 0.42174
178/178 [==============================] - 32s 177ms/step - loss: 0.3087 - accuracy: 0.8629 - val_loss: 0.4722 - val_accuracy: 0.7962
Epoch 15/100
178/178 [==============================] - ETA: 0s - loss: 0.3010 - accuracy: 0.8687
Epoch 15: val_loss did not improve from 0.42174
178/178 [==============================] - 33s 188ms/step - loss: 0.3010 - accuracy: 0.8687 - val_loss: 0.5373 - val_accuracy: 0.7921
Epoch 16/100
178/178 [==============================] - ETA: 0s - loss: 0.2954 - accuracy: 0.8647
Epoch 16: val_loss did not improve from 0.42174
178/178 [==============================] - 34s 188ms/step - loss: 0.2954 - accuracy: 0.8647 - val_loss: 0.4295 - val_accuracy: 0.8003
Epoch 17/100
178/178 [==============================] - ETA: 0s - loss: 0.2860 - accuracy: 0.8726
Epoch 17: val_loss did not improve from 0.42174
178/178 [==============================] - 32s 180ms/step - loss: 0.2860 - accuracy: 0.8726 - val_loss: 0.4855 - val_accuracy: 0.7745
Epoch 18/100
178/178 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.8844
Epoch 18: val_loss did not improve from 0.42174
178/178 [==============================] - 32s 176ms/step - loss: 0.2702 - accuracy: 0.8844 - val_loss: 0.4760 - val_accuracy: 0.7908
Epoch 19/100
178/178 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.8876
Epoch 19: val_loss did not improve from 0.42174
178/178 [==============================] - 32s 180ms/step - loss: 0.2584 - accuracy: 0.8876 - val_loss: 0.4502 - val_accuracy: 0.8098

# CÃ¡i nÃ y lÃ  cháº¡y cho global avg dense 4096

# Now, when you call predict, the order of the data will be the same as the order of the labels
y_true = test_generator.classes
y_pred = finetuned_model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)

# Calculate confusion matrix
confusion_mtx = confusion_matrix(y_true, y_pred_classes)

print("Confusion Matrix:")
print(confusion_mtx)

# Print classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred_classes))

Model architecture:
Model: "model_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_7 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 vgg16 (Functional)          (None, 7, 7, 512)         14714688  
                                                                 
 global_average_pooling2d_1  (None, 512)               0         
  (GlobalAveragePooling2D)                                       
                                                                 
 dense_9 (Dense)             (None, 1024)              525312    
                                                                 
 dropout_6 (Dropout)         (None, 1024)              0         
                                                                 
 dense_10 (Dense)            (None, 1024)              1049600   
                                                                 
 dropout_7 (Dropout)         (None, 1024)              0         
                                                                 
 dense_11 (Dense)            (None, 3)                 3075      
                                                                 
=================================================================
Total params: 16292675 (62.15 MB)
Trainable params: 1577987 (6.02 MB)
Non-trainable params: 14714688 (56.13 MB)


Confusion Matrix:
[[389  18   0]
 [ 15 338  54]
 [  6  60 341]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.96      0.95       407
           1       0.81      0.83      0.82       407
           2       0.86      0.84      0.85       407

    accuracy                           0.87      1221
   macro avg       0.87      0.87      0.87      1221
weighted avg       0.87      0.87      0.87      1221





