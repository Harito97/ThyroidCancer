{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'D:/Projects/ThyroidCancer/Data/slice_datav1'\n",
    "TARGET_SIZE = (224, 224)\n",
    "BATCH_SIZE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Đếm số lượng mẫu trong mỗi nhãn\n",
    "label_counts = [41, 216, 312]  # Số lượng mẫu của các nhãn tương ứng\n",
    "\n",
    "# Tính toán trọng số cho mỗi nhãn\n",
    "max_count = max(label_counts)\n",
    "class_weights = [max_count / count for count in label_counts]\n",
    "\n",
    "# Tạo mảng trọng số tương ứng với từng mẫu\n",
    "sample_weights = np.array([class_weights[label] for label in [0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 569 images belonging to 3 classes.\n",
      "Found 287 images belonging to 3 classes.\n",
      "Found 569 images belonging to 3 classes.\n",
      "Class Indices:  {'B2': 0, 'B5': 1, 'B6': 2}\n",
      "Number of training samples: 569\n",
      "Number of validation samples: 287\n",
      "Number of test samples: 569\n",
      "Training set:\n",
      "B2 (0): 41 files\n",
      "B5 (1): 216 files\n",
      "B6 (2): 312 files\n",
      "Validation set:\n",
      "B2 (0): 41 files\n",
      "B5 (1): 216 files\n",
      "B6 (2): 312 files\n",
      "Test set:\n",
      "B2 (0): 21 files\n",
      "B5 (1): 109 files\n",
      "B6 (2): 157 files\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'train'),\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'test'),\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(DATA_DIR, 'valid'),\n",
    "    target_size=TARGET_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Display information\n",
    "print(\"Class Indices: \", train_generator.class_indices)\n",
    "print(f\"Number of training samples: {train_generator.samples}\")\n",
    "print(f\"Number of validation samples: {valid_generator.samples}\")\n",
    "print(f\"Number of test samples: {test_generator.samples}\")\n",
    "\n",
    "print(\"Training set:\")\n",
    "for class_name, idx in train_generator.class_indices.items():\n",
    "    num_files = len(os.listdir(os.path.join(DATA_DIR, 'train', class_name)))\n",
    "    print(f\"{class_name} ({idx}): {num_files} files\")\n",
    "\n",
    "print(\"Validation set:\")\n",
    "for class_name, idx in valid_generator.class_indices.items():\n",
    "    num_files = len(os.listdir(os.path.join(DATA_DIR, 'valid', class_name)))\n",
    "    print(f\"{class_name} ({idx}): {num_files} files\")\n",
    "\n",
    "print(\"Test set:\")\n",
    "for class_name, idx in test_generator.class_indices.items():\n",
    "    num_files = len(os.listdir(os.path.join(DATA_DIR, 'test', class_name)))\n",
    "    print(f\"{class_name} ({idx}): {num_files} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample counts after augmentation:\n",
      "Training set:\n",
      "B2: 41 samples\n",
      "B5: 216 samples\n",
      "B6: 312 samples\n",
      "Validation set:\n",
      "B2: 21 samples\n",
      "B5: 109 samples\n",
      "B6: 157 samples\n",
      "Test set:\n",
      "B2: 41 samples\n",
      "B5: 216 samples\n",
      "B6: 312 samples\n"
     ]
    }
   ],
   "source": [
    "# Function to count the number of samples in each class\n",
    "def count_samples(generator, class_indices):\n",
    "    sample_counts = {class_name: 0 for class_name in class_indices.keys()}\n",
    "    \n",
    "    for _ in range(len(generator)):\n",
    "        _, labels = next(generator)\n",
    "        for label in labels:\n",
    "            class_name = list(class_indices.keys())[np.argmax(label)]\n",
    "            sample_counts[class_name] += 1\n",
    "    \n",
    "    return sample_counts\n",
    "\n",
    "# Count the number of samples in each class after augmentation\n",
    "train_counts = count_samples(train_generator, train_generator.class_indices)\n",
    "valid_counts = count_samples(valid_generator, valid_generator.class_indices)\n",
    "test_counts = count_samples(test_generator, test_generator.class_indices)\n",
    "\n",
    "# Print the sample counts\n",
    "print(\"Sample counts after augmentation:\")\n",
    "print(\"Training set:\")\n",
    "for class_name, count in train_counts.items():\n",
    "    print(f\"{class_name}: {count} samples\")\n",
    "\n",
    "print(\"Validation set:\")\n",
    "for class_name, count in valid_counts.items():\n",
    "    print(f\"{class_name}: {count} samples\")\n",
    "\n",
    "print(\"Test set:\")\n",
    "for class_name, count in test_counts.items():\n",
    "    print(f\"{class_name}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(history):\n",
    "    acc = pd.Series(history.history[\"accuracy\"], name=\"accuracy\")\n",
    "    loss = pd.Series(history.history[\"loss\"], name=\"loss\")\n",
    "    val_acc = pd.Series(history.history[\"val_accuracy\"], name=\"val_accuracy\")\n",
    "    val_loss = pd.Series(history.history[\"val_loss\"], name=\"val_loss\")\n",
    "    com = pd.concat([acc, loss, val_acc, val_loss], axis=1)\n",
    "    com.to_csv(\"slice_datav1_vgg0_1_history.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"Model Accuracy and Loss\")\n",
    "    plt.ylabel(\"Accuracy/Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"accuracy\", \"val_accuracy\", \"loss\", \"val_loss\"], loc=\"upper right\")\n",
    "    plt.savefig(\"slice_datav1_vgg0_1_model_accuracy_loss.png\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inp = Input((224, 224, 3))\n",
    "base_model = tf.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model(Inp)\n",
    "x = Flatten()(x)\n",
    "# x = GlobalAveragePooling2D()(x) # số lượng đặc trưng được duỗi ra là 512\n",
    "x = Dense(4096, activation='relu')(x)  \n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(4096, activation='relu')(x)   \n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(classes), activation=\"softmax\")(x)\n",
    "finetuned_model = Model(inputs=Inp, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">102,764,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,291</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │   \u001b[38;5;34m102,764,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │        \u001b[38;5;34m12,291\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,272,835</span> (512.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,272,835\u001b[0m (512.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,558,147</span> (456.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m119,558,147\u001b[0m (456.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Model architecture:')\n",
    "finetuned_model.summary()\n",
    "\n",
    "finetuned_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "for c in train_generator.class_indices:\n",
    "    classes[train_generator.class_indices[c]] = c\n",
    "finetuned_model.classes = classes\n",
    "early_stopping = EarlyStopping(patience=5*2)\n",
    "checkpointer = ModelCheckpoint(\n",
    "    \"vgg0.1_best_slice_datav1.keras\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_generator(train_generator, test_generator):\n",
    "    while True:\n",
    "        for data in train_generator:\n",
    "            yield data\n",
    "        for data in test_generator:\n",
    "            yield data\n",
    "\n",
    "combined_gen = combined_generator(train_generator, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert generators to tf.data.Dataset\n",
    "def generator_to_tfdata(generator):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, TARGET_SIZE[0], TARGET_SIZE[1], 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 3), dtype=tf.float32),\n",
    "        )\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = generator_to_tfdata(combined_gen).repeat()\n",
    "valid_dataset = generator_to_tfdata(valid_generator).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.6097561 , 1.44444444, 1.        ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your class weights\n",
    "class_weights = {0: sample_weights[0], 1: sample_weights[1], 2: sample_weights[2]}  # replace with your actual weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train step: 95\n",
      "Num valid step: 24\n",
      "Classes: ['B2', 'B5', 'B6']\n"
     ]
    }
   ],
   "source": [
    "# Tính số bước cho mỗi epoch\n",
    "num_train_steps = math.ceil(train_generator.samples * 2 / BATCH_SIZE)\n",
    "num_valid_steps = math.ceil(valid_generator.samples / BATCH_SIZE)\n",
    "classes = list(iter(train_generator.class_indices))\n",
    "print(f'Num train step: {num_train_steps}\\nNum valid step: {num_valid_steps}\\nClasses: {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4781 - loss: 2.6367\n",
      "Epoch 1: val_loss improved from inf to 1.01919, saving model to vgg0.1_best_slice_datav1.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 3s/step - accuracy: 0.4785 - loss: 2.6339 - val_accuracy: 0.5784 - val_loss: 1.0192\n",
      "Epoch 2/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5919 - loss: 1.6632\n",
      "Epoch 2: val_loss improved from 1.01919 to 0.81966, saving model to vgg0.1_best_slice_datav1.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 3s/step - accuracy: 0.5921 - loss: 1.6622 - val_accuracy: 0.6098 - val_loss: 0.8197\n",
      "Epoch 3/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6585 - loss: 1.2562\n",
      "Epoch 3: val_loss did not improve from 0.81966\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 3s/step - accuracy: 0.6587 - loss: 1.2546 - val_accuracy: 0.5679 - val_loss: 1.0845\n",
      "Epoch 4/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7222 - loss: 0.7528\n",
      "Epoch 4: val_loss improved from 0.81966 to 0.69974, saving model to vgg0.1_best_slice_datav1.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 3s/step - accuracy: 0.7227 - loss: 0.7522 - val_accuracy: 0.6620 - val_loss: 0.6997\n",
      "Epoch 5/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8285 - loss: 0.5968\n",
      "Epoch 5: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 3s/step - accuracy: 0.8286 - loss: 0.5961 - val_accuracy: 0.6655 - val_loss: 0.7083\n",
      "Epoch 6/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8773 - loss: 0.4307\n",
      "Epoch 6: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 3s/step - accuracy: 0.8775 - loss: 0.4300 - val_accuracy: 0.7143 - val_loss: 0.7620\n",
      "Epoch 7/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9039 - loss: 0.2943\n",
      "Epoch 7: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 3s/step - accuracy: 0.9040 - loss: 0.2940 - val_accuracy: 0.7178 - val_loss: 0.7242\n",
      "Epoch 8/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9382 - loss: 0.1994\n",
      "Epoch 8: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 3s/step - accuracy: 0.9383 - loss: 0.1995 - val_accuracy: 0.7003 - val_loss: 0.7859\n",
      "Epoch 9/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9549 - loss: 0.1815\n",
      "Epoch 9: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 3s/step - accuracy: 0.9549 - loss: 0.1814 - val_accuracy: 0.7073 - val_loss: 0.9931\n",
      "Epoch 10/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9624 - loss: 0.1399\n",
      "Epoch 10: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 3s/step - accuracy: 0.9624 - loss: 0.1399 - val_accuracy: 0.6794 - val_loss: 1.2369\n",
      "Epoch 11/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9554 - loss: 0.1318\n",
      "Epoch 11: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 3s/step - accuracy: 0.9554 - loss: 0.1318 - val_accuracy: 0.6899 - val_loss: 1.1222\n",
      "Epoch 12/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9677 - loss: 0.1071\n",
      "Epoch 12: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 3s/step - accuracy: 0.9676 - loss: 0.1071 - val_accuracy: 0.6829 - val_loss: 0.9424\n",
      "Epoch 13/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9792 - loss: 0.0798\n",
      "Epoch 13: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 3s/step - accuracy: 0.9792 - loss: 0.0799 - val_accuracy: 0.7143 - val_loss: 1.0416\n",
      "Epoch 14/100\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9717 - loss: 0.0945\n",
      "Epoch 14: val_loss did not improve from 0.69974\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 3s/step - accuracy: 0.9718 - loss: 0.0943 - val_accuracy: 0.7108 - val_loss: 1.0970\n"
     ]
    }
   ],
   "source": [
    "# Update the fit() function to remove the sample_weights parameter\n",
    "History = finetuned_model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=num_train_steps,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, checkpointer],\n",
    "    validation_data=valid_dataset,\n",
    "    validation_steps=num_valid_steps,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 1s/step - accuracy: 0.6355 - loss: 1.5590\n"
     ]
    }
   ],
   "source": [
    "accuracy = finetuned_model.evaluate(test_generator, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6994727849960327, 'loss': 1.135553240776062}\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.6341 - loss: 1.5681\n"
     ]
    }
   ],
   "source": [
    "accuracy = finetuned_model.evaluate(test_generator, steps=47, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6968085169792175, 'loss': 1.1455230712890625}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9942 - loss: 0.0184\n"
     ]
    }
   ],
   "source": [
    "accuracy = finetuned_model.evaluate(train_dataset, steps=num_train_steps, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9928951859474182, 'loss': 0.019867219030857086}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
